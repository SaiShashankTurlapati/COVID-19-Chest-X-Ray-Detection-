# Deep Learning Models for Analysing Corona Using Chest X-Ray Images 
Abstract— In the current era of the pandemic, as the months, have passed and the entire world is waiting for the crown vaccine to arrive then there ends the pandemic period. But it is practically not that easy and you may have to wait that long. Coronavirus is a large family of viruses that affects humans and damages respiratory functions ranging from the cold to more serious diseases such as ARDS, SARS. But the most recently discovered virus causes COVID-19 disease. In general, if a person is identified with mild symptoms, they are admitted to hospitals for a period of quarantine of 14 to 15 days and if he/she tests negative, they will be sent home. But if they test positive, they remain isolated in hospitals until they recover from the virus, and this does not have a specific period. Isolation at the home or hospital depends on one’s health history and conditions. Due to the prevailing disease that might get instigated due to the existence of the virus might lead to deterioration in health. Therefore, there is a need for early detection of the virus. Recently, many works are found to be observed with the deployment of techniques for the detection based on the chest x-rays. In this work, a solution has been proposed which consists of a sample prototype of an AI-based Flask-driven web application framework that predicts the six different diseases including ARDS, Bacteria, COVID, SARS, Streptococcus, Virus. Here, each category of X-ray images was placed under scrutiny and conducted training and testing using deep learning algorithms such as CNN, ResNet (With & With-out drop-out), VGG16, and AlexNet  to detect the status of X-rays.
Keywords— Deep Learning, CNN, Flask, Rectified Linear Units, Dense Layers
Introduction 
Corona Virus Disease (COVID-19) pandemic is a global challenge. This new respiratory virus has put an unprecedented load over health care systems in the world due to the exponential increase in the number of patients with COVID-19. In many countries, there is a limited number of diagnosis kits, personal protective equipment (PPE) kits, hospital beds for such patients, and limited ventilators. Also, infected individuals are often asymptomatic for many days. So, early identification of infected individuals can enable quarantining of the individuals and thus control the spread of the disease.  It has been inferred from various reports that there are more number of individuals infected with the COVID-19 experience direct respiratory ailment whereas a few others met with the destructive pneumonia. There are few conventions that the aged people who have history of disease that are associated with diabetes, infections in respiratory and malicious growth are tend to be associated with the other genuine disease [1]. 
There are three types of tests available for the detection of the virus. The first one is the molecular test also known as the real-time reverse transcription-polymerase chain reaction (RT-PCR). Most molecular test swabs must be kept within a certain temperature range so that the test will be accurate. The sample must arrive at the lab within 72 hours. It had a relatively low positive rate in the evaluation of COVID-19 (named world health organization). The second one is the antigen test and it is also known as a rapid diagnostic test. The sample is taken from the nasal or throat swab. With this test, positive results are usually highly accurate but negative results may need to be confirmed with a molecular test. The third test is an antibody test which is also identified as serology or blood test.  Antibody tests may provide quick results but should not be used to diagnose an active infection. The objective of the antibody tests is to only detect antibodies the immune system develops in response to the virus, not the virus itself. It can take days to several weeks to develop enough antibodies to be detected in a test.
Due to the low sensitivity rate (60%–70%) of the above traditional tests, even if negative results are obtained, symptoms can be detected by examining radiological images of patients. Chest radiological imaging such as computed tomography (CT) and X-ray have vital roles in the early diagnosis and treatment of this disease. The use of X-ray has several advantages over conventional diagnostic tests such as cost-effective, fast diagnostic results as it does not require any transportation from the acquisition, reduction of the requirement of additional PPE kits, and less risk due to the isolation ward for portable X-ray machines. This is not that easy as a model needs to make even minor parts of the X-Ray into scrutiny and classify the state of a person. The main contributions to this work have been stated as follows:
•	The developed model uses Convolution Neural Network a deep learning model to classify the diseases from the given image.
•	The prediction is of seven categories that include Normal, ARDS, Bacteria, COVID-19, SARS, Streptococcus, and Virus. 
•	Based on the prediction one can ensure his/her medical condition and may take necessary precautions to prevent the severe conditions in the earlier stage itself, which is the main goal of this work.
  A.  RELATED WORKS

Researchers have deployed various deep learning techniques for the detection of pneumonia and additionally the classification of viral and bacterial pneumonia in 2D pediatric chest radiographs is also performed. The authors [2] have devised a prediction model that uses a deep convolution neural network and prepared trained models such as Inception-ResNetV2, ResNet50, Inception-ResNetV2. Innovations observed from this work were
 1) End-to-end structure that does feature selection and extraction automatically 
2) Among the other pre-trained models, ResNet50 is found to be an efficient model. 
3) The best tool used for detecting the COVID-19 is the chest x-ray images. 
4) Through the pre-trained models, it has been proven that it results in high accuracy when the model is examined on the small dataset (50 COVID-19 vs. 50 Normal).  
Determination of COVID-19 persons could be done by investigating the chest x-ray images with the help of machine learning techniques. In [3], a method has been devised to classify the chest x-ray image that depends on the combination of the image descriptor (Fractional Multichannel Exponent Moments) FrMeMs and the improved attribute selection that depends on Manta-Ray Foraging Optimization and differential evolution (MRFODE). The first technique is used to excerpt the x-ray images of the chest. Then, it is partitioned into the training and testing sets. The inappropriate and redundancy features are removed by the deployment of MRFODE. Through this procedure, a group of solutions is obtained and the fitness value is computed for all the solutions by applying the KNN classifier on the training datasets. Later, the probability of each solution is calculated with the fitness value. The solutions are improved by the deployment of differential evolution or the functions of MRFO. Modifications are done until it reaches the termination condition. It is identified as the best solution for eradicating the inappropriate features and thus the labels for the image dataset are calculated. The proposed technique showed that there is an accuracy of 96.09% and 98.09% for the datasets correspondingly. 
A deep learning neural network model CoroNet has been proposed in [4] for the automatic detection of infection from the chest x-ray images. The principle behind this model is the Xception architecture that is pre-trained on the ImageNet dataset. It is trained completely on the training dataset of COVID-19 and other chest pneumonia x-ray images. The model is deployed to categorize the pneumonia types such as viral pneumonia, bacterial pneumonia, and COVID-19 pneumonia. The results are compared for further analysis. This model facilitates doctors during the triage and in monitoring the positive cases. An average accuracy of 89.6% on each fold, whereas certain metrics such as F1-Score, precision, recall, and average accuracy obtained are 95.61%,93.17%,98.25%, and 96.6% for the 4-class CoroNet Model. A few modifications to the model have been done and the parameters are tunes in such a way that it is tested on three classes only. The overall accuracy has been improved to 94.95% after the combination of the two non-covid-19 pneumonia infections.
In [5], five various data repositories such as Covid-19 Image data collection [6], Chest x-ray dataset initiative [7], ActualMed Covid-19 Chest x-ray Dataset initiative [8] collaborated with ActualMed, Covid-19 radiography database [9]and RSNA Pneumonia detection challenge dataset [10] that uses the widely available data [11] have been collected and modified. The dataset is constructed by obtaining certain patient cases from all repositories and they are described as given below.
•	Patients who suffer from Covid-19 and as well as the pneumonia patient cases from the Covid-19 Image data collection
•	Covid-19 patients from the Chest x-ray dataset initiative and the ActualMed dataset Initiative
•	Normal cases and pneumonia patients those who don’t have pneumonia but they suffer from RSNA pneumonia detection challenge dataset and finally, patients’ information has been extracted from the radiography database. From the experimental results, it has been observed that the model shows a test accuracy of 93.3%.
Prior diagnosis of patients infected with Covid-19 is done by the deep learning models combined in a framework named (COVIDX-Net) [12]. The cost of analysis is less due to that the testing has been done on traditional chest x-ray images. With the small datasets, the accuracy obtained is good and thereby the classification is done efficiently. The proposed framework is built on seven deep learning classifiers such as ResNetV2, Xception, VGG19, InceptionV3, DenseNet121, and InceptionResNetV2. From the experimental results, the performance scores obtained through the deployment of DenseNet201 and VGG19 proved to be the best score.
The authors [13] have focused on detecting the newly emerged virus with the framework based on deep learning. The framework is used to retrieve the local and overall features. Detection is made possible with the help of raw chest X-ray images. From the results, the classification accuracy obtained for the binary classification is 98.08% and 87.02% for multi-class classification. The classifier implemented by the authors was a DarkNet Model and 17 convolutional layers have been deployed in this framework. Additionally, filtering concepts have been used on each layer.
A three-dimensional deep learning framework has been recommended in [14]. In this, COVID-19 detection neural network (COVNet). The model is tested with various images such as community-acquired pneumonia(CAP) and other non-pneumonia lung diseases. RestNet50[15] supports the framework in which a series of CT slices is provided as the input and thereby features are generated based on it. The features thus extracted are joined with the help of max-pooling operation. Finally, the feature map thus generated is given as an input to the fully connected layer. The probability score is created through the softmax activation function for all types. As per the convention strategy, the CT image is first pre-processed and the lung region is extracted through the Unet[16] that depends on the segmentation method. Finally, the predictions are performed.
In the study [17] performed by the authors, the dataset has been created with 5,000 images of chest x-ray images. Testing is done on images that show a clear sign. Four deep learning models are deployed on the training dataset and the performance is examined on the test set. The transfer learning method was implemented so that the fine-tuning of models has been done on the COVID X-ray 5k dataset. The test set comprises 3000 images. Through this, performance metrics such as sensitivity and specificity are measured. It shows a rate of 98% and 92% respectively. Various other metrics such as precision-recall, Receiver Operating Characteristics (ROC) are measured. Additionally, the authors have shown the analysis through the heat maps that show the infected area concerning Covid-19 by this devised deep visualization method.

In [18], a concatenated neural network has been devised based on the principle of Xception and ResNet50V2 networks to classify the chest X-ray images. Infection due to ARDS, Pneumocystis, Streptococcus, SARS, and several other kinds of pneumonia have been shown in the dataset through the X-ray and CT scan images. An accuracy of 99.50% and 80.53% has been obtained for the COVID-19 and also, the accuracy 0f 91.4% is achieved among five folds. 

A classification model has been suggested by the authors [19] to categorize the patients from chest CT images. In this study, the dataset is segregated into training and test dataset. The proposed model works based on the principle of MODE-based CNN. Overfitting is provided by the utilization of 20-fold cross-validation. Several factors are taken into the consideration for comparing the proposed classification model. From the experimental results, the deployed ANN, ANFIS, and CNN models show an improvement in F-measure, sensitivity, specificity, and accuracy of 2.0928%,1.8262%, 1.6827%,1.9789% correspondingly.
Prediction of the number of patients who are infected with COVID-19 has been done with the deployment of ML models. In this work [20], models such as Least Absolute Shrinkage and Selection Operator(LASSO), Linear regression(LR), Exponential Smoothing, and Support Vector Machine (SVM) have been used in the prediction of the factors that cause threats in COVID-19. Predictions like the death rate, recoveries count, and the number of new infections are done. From the experimental results, it has been proven that the performance of the Exponential Smoothing is better when compared with the other models. LR and LASSO models perform better when compared with the SVM.    In the proposed work [21], a deep convolutional neural network (CNN) is used for detecting COVID-19 patients. Experimental results showed an F-measure of 95-99%. Inferences were made from 1000 X-ray images of patients. Predictions were done based on the methods such as the prophet algorithm (PA), autoregressive integrated moving average (ARIMA) model, and long short-term memory neural network (LSTM). Through this, the count of deaths, recovery rate, and confirmation cases was also determined. Average accuracy of 94.80% and 88.43% has been achieved through this model. Thus, the most affected cities have been identified and it has been observed that the number of cases is more in the coastal areas when compared with the non-coastal areas. Detection of coronavirus with the help of X-ray images have been done with the deployment of the deep learning model. The model [22] made use of SVM to categorize the infected images through deep features. It proves an accuracy, kappa, MCC, FPR and F1 score as 95.38%,90.76%,91.41%, 6.5% and 95.52% correspondingly. From various inferences, it has been shown that ResNet50 with SVM has shown a remarkable performance when compared with other classifiers. Synthetic chest x-ray images have been constructed with the help of an Auxiliary Classifier Generative Adversarial Network (ACGAN) based model called CovidGAN [23]. Performance of the model has been augmented and thus 85% of accuracy has been achieved. Accuracy is increased by 10% through the inclusion of synthetic images that has been constructed from the model. A comparison of a few works has been shown in table 1.







Table 1: Comparison of a few works
S.No	Model		Inferences
1	Xception and ResNet50V2[27]	X-ray images	Learning used is Transfer learning
Precision is low and the dataset is unbalanced
Accuracy is better 
2	Decompose, Transfer, and Compose (DeT raC) model	X-ray images	Learning used is Transfer learning
Accuracy – 95.12%
3	CovidGAN	Synthetic X-ray images	Accuracy -95%
4	AlexNet, GoogLeNet, Squeeznet, and Resnet18 are selected as deep transfer learning models	X-ray images of two categories namely Normal and Pneumonia.	An appropriate model that shows an accuracy of 99%
Many works have been focused recently on the utilization of convolutional neural networks (CNNs) to solve common problems in the field of image classification. CNN's were built at first to classify images; they do so by using successive layers of convolutions and pooling. When training a traditional CNN, more focus has been done to check whether the model predicts the right classification or not. The pooling layer in a convolutional block is used to reduce the data dimension and achieve something called spatial invariance, which means regardless of where the object is placed in the image, it identifies the object and classifies it.
B.  CNN MODEL STRUCTURE  

This section discusses the complete architecture and working of the model that classifies the state of Chest X-Ray.
Machine Learning algorithms are widely being used for the classification of images, data, etc., However, in this work, we proposed a deep learning algorithm - convolutional neural network technique to predict the coronavirus using chest x-ray image.
The proposed COVID prediction model is based on convolutional neural networks (CNN). Among the available deep learning algorithms, the objective of selecting the CNN is that this algorithm deals with images and it has been observed from various inferences that it is one of the best ways to classify the images. The basic working of CNN would be like a categorical value of inputs (segregated images) were taken and then resizing of images is done with Image Data Generator. Later the data is being passed through various layers of CNN and then prioritizes various objects such as the content of pneumonia in our case and other patterns in the image and thereby classifies/differentiates each category of images (Chest X-rays). The model architecture has been depicted in figure 1.
 
                           Fig. 1. – Model Architecture
The convolutional neural network is a combination of Convolutional Layers and a Neural network. To deploy it, we have made use of Keras- a Neural Network library that works as a wrapper to low-level libraries like TensorFlow. There are two types of models in Keras namely Sequential and Functional. We choose sequential over functional because the sequential model deals with the linear stack of layers whereas the functional model deals with the arbitrary graph of layers. The Sequential Keras model contains Max-pooling Layer, Convolution Layer, and Flatten Layer. Here, the neural network consisting of 4 layers which are the Input Layer, Convolutional Layer, Pooling Layer, Dense Layer. The Dense Layer contains 3 more layers which are Input Layer, Hidden Layer, and output Layer. 
A specific approach has been adopted and the traditional convolutional network - Rectified Linear Unit (ReLU) as the activation function has been implemented to extract the basic features of the image so that the model could predict the accuracy perfectly. The input image provided to the input layer is resized to 150x150 after applying the initial preprocessing step. Each pixel is considered as xi. The input layer is of size 150*150*3. The activation of a node defines the output of that node given a set of inputs. The Rectified Linear Unit is the most commonly used in deep learning models. This is basic functionality that returns 0 if a negative value as input is given and if the positive input is given, it returns the particular value. 
 
            Fig. 2. – Sample Chest X-Ray dataset [24]

The activation function of the 7 output dimensions we used is softmax as the final layer in the proposed model. The softmax activation function is normally applied to the very last layer in the neural network. The reason why softmax is useful because it converts the output of the last layer in the network into what is essentially a probability distribution. The softmax activation function is given by the below equation.

             Softmax= SM(xi)= exi /∑ nj=1 exi

The loss of the proposed model is predicted with the cross-entropy given by 
               
              Loss(p,e)=-∑p(xi)log(e(xi))

Where p is the probability distribution of each pixel.
The proposed method is graphically represented in the below figure.
 
Fig 3- Proposed CNN model
C.  RESNET MODEL STRUCTURE
This section discusses the complete architecture of the deep learning model used i.e., Residual Network (ResNet) without dropout. ResNet is one of the applications of Transfer learning. The best part of ResNet is that the algorithm can classify almost 1000 plus categories of the dataset. In the proposed model, ResNet50 is used. 
The model (ResNet) consists of Identity blocks and convolutional blocks of 5 stages each. The convolutional block has a further 3 layers and thereby identity block has 3 convolutional layers. The basic working of ResNet would be like a categorical value of inputs (segregated images) were taken and then resize the images with Image Data Generator. Later, the series of layers is passed such that the algorithm finds/identifies the unique patterns among the categories of images. 
For the last layer to be added in the model, there are few layers passed as input layers. The input layers are the Lambda layer, Dense layer, and Flatten layer. All these layers create a sequential model by passing a list/stage of layer instances to Keras. Keras works as a wrapper to low-level libraries like TensorFlow. The proposed ResNet model also follows the linear stack of layers. 
The input image provided to the input layer is resized to 244*244 after applying the initial preprocessing step. Then, the path for both the train data and valid(test) data must be passed. Later to remove the last layer and set all the required categories to it. So, initialize the input shape as image size (224,224) + [3]. Here, 3 indicates that the data set of images contains RGB images which are a non-grey scale. Weights of the layers are being given through the inbuilt function ImageNet. For removing the last layer, include_top = “False” must be given, such that the removed layer can be used for transfer learning.
As weights are fixed, this model doesn’t have to train all the layers of the Resnet because it is a state of heart algorithm. Training all the layers makes the model reduce the accuracy because ResNet has been trained in many images. A lot of resources and GPU are required to train them. To avoid all these things, the proposed model made sure that every single layer in the ResNet layer isn’t training. Now, the last layer is flattened and appends the number of classes. As a dense layer with an activation function as SoftMax is assigned to a variable name prediction. 

The proposed method is graphically represented in the below figure.
 
Fig 4- Proposed ResNet Method

D. VGG16 AND ALEXNET MODEL STRUCTURE
This section discusses the VGG16 and AlexNet model used as a comparison among deep learning algorithms CNN and ResNet. Visual Geometry Group (VGG16) which is also known as OxfordNet. VGG16 is a convolutional neural network that is considered as one of the excellent vision model architectures and is 16 layers deep. It has large number of hyper-parameters mainly focused on convolutional layers of 3x3 filter layer with stride 1 and always used same padding and maxpooling layer of 2x2 filter of stride 2.  It has almost 138 million parameters where as ResNet has only 25.5 million parameters. In the final layer it has two fully connected layers and then followed by softmax for the output.
The steps of VGG16 from initialization to compilation is as follows, a sequential model is initialized, and then ImageDataGenerator functions is used to rescale, rotate, zoom, flip the images and labeling the data inside the folder. Later, the convolutional layers, max pooling layers of keras and padding are added. For the negative values being stopped to pass the next layers, relu activation layer is added to all the layers. To flatten the vector that comes out of convolutions, the data is passed to dense layers. Finally, the softmax layer is passed for the output. 
The proposed VGG16 method is graphically represented in the below figure,
Fig 5- Proposed VGG16 Method
One of the algorithms used to overcome the problem of image classification is AlexNet. It is made up of sixty million parameters. If the input size of the RGB image is 224 x 224, all of the training and test set images will be 224 x 224. The AlexNet's architecture is shown in the figure.       We can observe that AlexNet consists of 1 SoftMax layer, 2 Fully Connected Layers, 3 overlapping Max Pooling Layers, 2 normalization layers, and 5 Convolutional Layers from the architecture shown in Fig 6. Each convolution layer of the same image size has various kernel numbers.Initially, if we understand the architecture, a convolution layer of stride = 4 with 96 kernels of size 11 x 11 was used by overlapping the Max Pooling layers of size 3 x 3 with the next step = 2. Convolution layer 5 x 5 with padding size = 2 of 256 kernels has been completed. The overlapping Max pooling layer of phase = 2 with the image size of 3 x 3 follows it again.Then, three 384 kernel convolution layers of size 3 x 3 with padding size 2 are directly connected to each other. An Overlapping Max Pooling Layer of size 3 x 3 with phase = 2 follows next to it. Now, about two fully connected 4096unit layers that follow with an output layer, 1000-way SoftMax. This provides about 1000 class labels to be distributed.     Each convolution layer, together with a non-linear activation function, i.e., ReLU, contains convolution filters. ReLU is added after every convolution layer and the fully-connected layer. Dropout is applied prior to the two fully related layers. Dropout is a technique developed by G.E.Hinton where a neuron is dropped from a network so that either forward or backward propagation do not participate.       This raises the number of iterations and will greatly overfit the model without dropouts. Accuracy obtained via this model of AlexNet is relatively weak. Therefore, to increase the detection rate, this results in deploying another model.
The proposed AlexNet method is graphically represented in the below figure,
 
Fig 6- Proposed AlexNet Method
E. COMPARISION - RESNET, VGG16 & ALEXNET
Applying image classification in medical fields is not a new technique. Researchers around the world use different deep learning image classification algorithms, such as CNN and ResNet. The Residual Network (ResNet) with dropout algorithm makes it possible to train up to thousands of layers or even more and still achieves convincing performance. It remained an amazing algorithm in the deep learning community. Almost all researchers dived into the algorithm to discover the secrets of success. Thus, Resnet is also included in the proposed project. While the algorithm is a powerful concept, it does have some drawbacks.

However, for a particular type of model to be implemented, increasing the depth of the network, that is, stacking layers, may work. The same image data is used for CNN and ResNet, VGG16, and AlexNet. CNN algorithm got a 72% test precision for 20 epochs, while ResNet with dropout got 84% test precision for even 15 epochs each, whereas VGG16 results in 72% of test precision for 50 epochs, finally AlexNet resulted in 46% test precision for 100 epochs. To our surprise ResNet without dropout resulted in 98% test precision for only 5 epochs, which is actually the best and considerable models among all. Even though the dataset is chest X-ray images and it has fewer levels of patterns, ResNet itself has proven to be one of the best models in many applications, the downside is that the deepest network would require weeks of training and we assume that the other reason with the Residual Network for high accuracy would be with weight initializations.

Since, VGG16 was a pre-trained model which is trained for 1000 class classification while for the proposed project we used only 7 class classification. The algorithm also has so many weight parameters in which the models are very heavy that results in extensive inference time. All this is the reason for the low accuracy under-fit model when compared to ResNet50 and CNN algorithms. 

Compared to the models used in this paper AlexNet model has low depth and therefore, it is difficult for the algorithm to learn features of a set of this chest x-ray images.
F.  RESULTS AND DISCUSSION
The proposed approach is validated using the ieee8023 – COVID chest x-ray dataset. Figure 2 shows the sample dataset. Firstly, the actual data given is of 5,935 images in which, the images are split into 5252 train images and 683 test images. Since the given data is not classified and in a raw format and based on the detailed description of metadata of all the images given, we’ve segregated the complete data. As few of the categories like ARDS and SARS has very few amounts of data whereas Bacteria and Virus have a very large amount of data. 

The Data set of ieee8023 contains 7 different classes of images namely ARDS, Bacteria, COVID, Normal, SARS, Streptococcus, and Virus.

Table 2: The count of images dataset which is validated using a deep learning algorithm

 

The experimentation is performed by 80% of the training data and 20% of the testing dataset.

We choose to consider the ResNet (without dropout) model for further proceedings with web application development. Sinc it topped in the test precision accuracy of 98%.

Figure 5 shows the accuracy of the proposed network in regards to epochs i.e., Accuracy vs Epochs. Figure 6 shows the loss vs epochs comparison of ResNet(without dropout) model.

 
Fig. 7. – Accuracy vs. Epoch


 
Fig. 8. – Loss Vs. Epoch

After the model has been built we built a UI that was developed using HTML, CSS, and JavaScript. Later, we developed a python flask file. Flask is a web application that would be used to inter-link the back-end and front-end for the proposed project. Now, the proposed model is integrated into the web page with the deep learning model using Flask. 

Figure 9 shows the actual web page UI that we proposed in this paper.
 

Fig. 9. – The proposed web page user interface

Figure 10 shows the COVID chest X-ray image prediction through the user interface.
 

            Fig. 10. – COVID chest X-ray Prediction
REFERENCES
1. cdc. (2020). Coronavirus Disease 2019 (COVID-19). Available: https://www.cdc.gov/coronavirus/2019-ncov/need-extraprecautions/people-at-higher-risk.html.
2. Narin, Ali & Kaya, Ceren & Pamuk, Ziynet. (2020). Automatic Detection of Coronavirus Disease (COVID-19) Using X-ray Images and Deep Convolutional Neural Networks.
3. Elaziz MA, Hosny KM, Salah A, Darwish MM, Lu S, Sahlol AT (2020) New machine learning method for image-based diagnosis of COVID-19. PLoS ONE 15(6): e0235187. https://doi.org/ 10.1371/journal.pone.0235187.
4.A.I. Khan, J.L. Shah, M. Bhat, CoroNet: a deep neural network for detection and diagnosis of COVID-19 from chest x-ray images, arXiv:2004.04931(2020).
5.L. Wang, A. Wong, COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest radiography images, arXiv:2003.09871(2020).
6.Cohen, J. P., Morrison, P. & Dao, L. COVID-19 image data collection. arXiv 2003.11597 (2020). 
7.Chung, A. Figure 1 COVID-19 chest x-ray data initiative. https://github.com/agchung/Figure1-COVID-chestxray-dataset (2020). 
8.Chung, A. Actualmed COVID-19 chest x-ray data initiative. https://github.com/agchung/Actualmed-COVID-chestxray-dataset (2020). 11/12 
9. COVID-19 Radiography Database. https://www.kaggle.com/tawsifurrahman/covid19-radiography-database. Accessed 2 July 2020.

10. RSNA Pneumonia Detection Challenge. Radiological Society of North America. https://www.kaggle.com/c/ rsna-pneumonia-detection-challenge, 2018

11.Wang, X. et al. Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. In 2017 IEEE Conference on Computer Vision and Pattern Recognition(CVPR), 3462–3471 (2017).
12.Hemdan, E. E. D., Shouman, M. A., & Karar, M. E. (2020). Covidx-net: A framework of deep learning classifiers to diagnose covid-19 in x-ray images. arXiv preprint arXiv:2003.11055.
13.Ozturk, T., Talo, M., Yildirim, E. A., Baloglu, U. B., Yildirim, O., & Rajendra Acharya, U. (2020). Automated detection of COVID-19 cases using deep neural networks with X-ray images. Computers in biology and medicine, 121, 103792. https://doi.org/10.1016/j.compbiomed.2020.103792
14L. Li, L. Qin, Z. Xu, Y. Yin, X. Wang, B. Kong, J. Bai, Y. Lu, Z. Fang, Q. Song et al.Radiology (2020), p. 200905

15. He K, Zhang X, Ren S, et al. Deep residual learning for image recognition. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016. 
16. Ronneberger O, Philipp F, Thomas B. U-net: Convolutional networks for biomedical image segmentation. In: Navab N, Hornegger J, Wells W, Frangi A, eds. Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015. MICCAI 2015. Lecture Notes in Computer Science, vol 9351. Cham, Switzerland: Springer, 2015; 234–241https://doi.org/10.1007/978-3-319-24574-4_28.

17. Minaee, Shervin & Kafieh, Rahele & Sonka, Milan & Yazdani, Shakib & Jamalipour Soufi, Ghazaleh. (2020). Deep-COVID: Predicting COVID-19 From Chest X-Ray Images Using Deep Transfer Learning.
18. Rahimzadeh, Mohammad & Attar, Abolfazl. (2020). A modified deep convolutional neural network for detecting COVID-19 and pneumonia from chest X-ray images based on the concatenation of Xception and ResNet50V2. Informatics in Medicine Unlocked. 19. 100360. 10.1016/j.imu.2020.100360. 
19. Singh, D., Kumar, V., Vaishali, & Kaur, M. (2020). Classification of COVID-19 patients from chest CT images using multi-objective differential evolution-based convolutional neural networks. European journal of clinical microbiology & infectious diseases : official publication of the European Society of Clinical Microbiology, 39(7), 1379–1389. https://doi.org/10.1007/s10096-020-03901-z
20.Rustam, Furqan & Reshi, Aijaz & Mehmood, Arif & Ullah, Dr. Saleem & On, Byungwon & Aslam, Waqar & Choi, Gyu Sang. (2020). COVID-19 Future Forecasting Using Supervised Machine Learning Models. IEEE Access. PP. 1-1. 10.1109/ACCESS.2020.2997311. 
21. Alazab, Moutaz & Awajan, Albara & Mesleh, Abdelwadood & Abraham, Ajith & Jatana, Vansh & Alhyari, Salah. (2020). COVID-19 Prediction and Detection Using Deep Learning. 12. 168-181.
22. Sethy, P.K.; Behera, S.K. Detection of Coronavirus Disease (COVID-19) Based on Deep Features. Preprints 2020, 2020030300 (doi: 10.20944/preprints202003.0300.v1).
23. Waheed, Abdul & Goyal, Muskan & Gupta, Deepak & Khanna, Ashish & Al-Turjman, Fadi & Pinheiro, Plácido. (2020). CovidGAN: Data Augmentation using Auxiliary Classifier GAN for Improved Covid-19 Detection. IEEE Access. PP. 1-1. 10.1109/ACCESS.2020.2994762.
24. ieee8023/covid-chestxray-dataset. Retrieved July 19, 2020, from GitHub - https://github.com/ieee8023/covid-chestxray-dataset.

